"""
EVO-TR: ChromaDB Handler

Uzun sÃ¼reli hafÄ±za yÃ¶netimi iÃ§in ChromaDB entegrasyonu.
"""

import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
from datetime import datetime
import uuid
import json
from pathlib import Path


class MemoryHandler:
    """
    ChromaDB tabanlÄ± uzun sÃ¼reli hafÄ±za yÃ¶netimi.
    
    Ã–zellikler:
    - Persistent storage (kalÄ±cÄ± depolama)
    - Semantic search (anlamsal arama)
    - Metadata filtreleme
    - TÃ¼rkÃ§e/Ä°ngilizce destek
    """
    
    def __init__(
        self, 
        persist_path: str = "./data/chromadb",
        collection_name: str = "evo_memory",
        embedding_model: str = "paraphrase-multilingual-MiniLM-L12-v2"
    ):
        """
        MemoryHandler baÅŸlat.
        
        Args:
            persist_path: ChromaDB veritabanÄ± yolu
            collection_name: Collection adÄ±
            embedding_model: Sentence-transformer model adÄ±
        """
        self.persist_path = Path(persist_path)
        self.persist_path.mkdir(parents=True, exist_ok=True)
        
        # ChromaDB client
        self.client = chromadb.PersistentClient(path=str(self.persist_path))
        
        # Embedding modeli yÃ¼kle
        self._embedding_model = SentenceTransformer(embedding_model)
        self._embedding_dim = self._embedding_model.get_sentence_embedding_dimension()
        
        # Collection oluÅŸtur/al
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}  # Cosine similarity
        )
        
        print(f"âœ… MemoryHandler hazÄ±r | Collection: {collection_name} | Docs: {self.collection.count()}")
    
    def _generate_id(self) -> str:
        """Benzersiz ID Ã¼ret."""
        return str(uuid.uuid4())[:8]
    
    def _get_embedding(self, text: str) -> List[float]:
        """Metin iÃ§in embedding vektÃ¶rÃ¼ Ã¼ret."""
        return self._embedding_model.encode(text).tolist()
    
    def add_memory(
        self, 
        text: str, 
        metadata: Optional[Dict[str, Any]] = None,
        memory_type: str = "conversation"
    ) -> str:
        """
        Yeni hafÄ±za ekle.
        
        Args:
            text: Kaydedilecek metin
            metadata: Ek bilgiler (intent, topic, vb.)
            memory_type: HafÄ±za tipi (conversation, fact, preference, code)
        
        Returns:
            OluÅŸturulan belge ID'si
        """
        doc_id = self._generate_id()
        
        # Metadata hazÄ±rla
        meta = {
            "type": memory_type,
            "timestamp": datetime.now().isoformat(),
            "text_length": len(text)
        }
        
        if metadata:
            meta.update(metadata)
        
        # Embedding oluÅŸtur ve ekle
        embedding = self._get_embedding(text)
        
        self.collection.add(
            ids=[doc_id],
            embeddings=[embedding],
            documents=[text],
            metadatas=[meta]
        )
        
        return doc_id
    
    def add_conversation(
        self, 
        user_message: str, 
        assistant_response: str,
        intent: Optional[str] = None,
        topic: Optional[str] = None
    ) -> str:
        """
        KonuÅŸma Ã§iftini hafÄ±zaya ekle.
        
        Args:
            user_message: KullanÄ±cÄ± mesajÄ±
            assistant_response: Asistan yanÄ±tÄ±
            intent: Tespit edilen intent
            topic: Konu baÅŸlÄ±ÄŸÄ±
        
        Returns:
            Belge ID'si
        """
        # KonuÅŸmayÄ± birleÅŸtir (arama iÃ§in)
        combined_text = f"KullanÄ±cÄ±: {user_message}\nAsistan: {assistant_response}"
        
        metadata = {
            "user_message": user_message[:500],  # KÄ±rp (metadata limiti)
            "assistant_response": assistant_response[:500],
        }
        
        if intent:
            metadata["intent"] = intent
        if topic:
            metadata["topic"] = topic
        
        return self.add_memory(
            text=combined_text,
            metadata=metadata,
            memory_type="conversation"
        )
    
    def search(
        self, 
        query: str, 
        top_k: int = 3,
        memory_type: Optional[str] = None,
        min_score: float = 0.3
    ) -> List[Dict[str, Any]]:
        """
        Semantik arama yap.
        
        Args:
            query: Arama sorgusu
            top_k: DÃ¶ndÃ¼rÃ¼lecek maksimum sonuÃ§ sayÄ±sÄ±
            memory_type: Filtrelenecek hafÄ±za tipi
            min_score: Minimum benzerlik skoru (0-1)
        
        Returns:
            Bulunan belgeler listesi
        """
        # Embedding oluÅŸtur
        query_embedding = self._get_embedding(query)
        
        # Where filtresi
        where_filter = None
        if memory_type:
            where_filter = {"type": memory_type}
        
        # Arama yap
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            where=where_filter,
            include=["documents", "metadatas", "distances"]
        )
        
        # SonuÃ§larÄ± formatla
        formatted_results = []
        
        if results["documents"] and results["documents"][0]:
            for i, doc in enumerate(results["documents"][0]):
                # Distance'Ä± similarity'ye Ã§evir (cosine distance -> similarity)
                distance = results["distances"][0][i]
                similarity = 1 - distance  # Cosine distance iÃ§in
                
                if similarity >= min_score:
                    formatted_results.append({
                        "id": results["ids"][0][i],
                        "text": doc,
                        "metadata": results["metadatas"][0][i],
                        "similarity": round(similarity, 3)
                    })
        
        return formatted_results
    
    def get_relevant_context(
        self, 
        query: str, 
        top_k: int = 3,
        max_tokens: int = 500
    ) -> str:
        """
        Sorgu iÃ§in ilgili baÄŸlam oluÅŸtur (RAG iÃ§in).
        
        Args:
            query: KullanÄ±cÄ± sorgusu
            top_k: Maksimum belge sayÄ±sÄ±
            max_tokens: Maksimum karakter (yaklaÅŸÄ±k token)
        
        Returns:
            FormatlanmÄ±ÅŸ baÄŸlam metni
        """
        results = self.search(query, top_k=top_k)
        
        if not results:
            return ""
        
        context_parts = []
        total_chars = 0
        
        for i, result in enumerate(results, 1):
            text = result["text"]
            meta = result["metadata"]
            sim = result["similarity"]
            
            # KÄ±sa versiyon oluÅŸtur
            if len(text) > 300:
                text = text[:300] + "..."
            
            part = f"[HafÄ±za {i}] (Benzerlik: {sim:.0%})\n{text}"
            
            if total_chars + len(part) > max_tokens * 4:  # ~4 char/token
                break
            
            context_parts.append(part)
            total_chars += len(part)
        
        if context_parts:
            return "ğŸ“š Ä°lgili HafÄ±za:\n" + "\n\n".join(context_parts)
        
        return ""
    
    def delete(self, doc_id: str) -> bool:
        """Belge sil."""
        try:
            self.collection.delete(ids=[doc_id])
            return True
        except Exception as e:
            print(f"âš ï¸ Silme hatasÄ±: {e}")
            return False
    
    def clear_all(self) -> int:
        """TÃ¼m hafÄ±zayÄ± temizle."""
        count = self.collection.count()
        
        # Collection'Ä± yeniden oluÅŸtur
        collection_name = self.collection.name
        self.client.delete_collection(collection_name)
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        
        print(f"ğŸ§¹ {count} belge silindi")
        return count
    
    def get_stats(self) -> Dict[str, Any]:
        """HafÄ±za istatistikleri."""
        count = self.collection.count()
        
        stats = {
            "total_documents": count,
            "collection_name": self.collection.name,
            "persist_path": str(self.persist_path),
            "embedding_dim": self._embedding_dim
        }
        
        # Tip daÄŸÄ±lÄ±mÄ±
        if count > 0:
            all_docs = self.collection.get(include=["metadatas"])
            type_counts = {}
            for meta in all_docs["metadatas"]:
                t = meta.get("type", "unknown")
                type_counts[t] = type_counts.get(t, 0) + 1
            stats["type_distribution"] = type_counts
        
        return stats


# Test
if __name__ == "__main__":
    print("ğŸ§ª MemoryHandler Testi\n")
    
    handler = MemoryHandler(
        persist_path="./data/chromadb/test",
        collection_name="test_memory"
    )
    
    # Temiz baÅŸla
    handler.clear_all()
    
    # KonuÅŸmalar ekle
    handler.add_conversation(
        user_message="Merhaba, benim adÄ±m Kaan",
        assistant_response="Merhaba Kaan! TanÄ±ÅŸtÄ±ÄŸÄ±mÄ±za memnun oldum. Sana nasÄ±l yardÄ±mcÄ± olabilirim?",
        intent="general_chat"
    )
    
    handler.add_conversation(
        user_message="Python'da bir liste nasÄ±l sÄ±ralarÄ±m?",
        assistant_response="Python'da liste sÄ±ralamak iÃ§in sorted() veya list.sort() kullanabilirsin.",
        intent="code_python"
    )
    
    handler.add_conversation(
        user_message="TÃ¼rk kahvesi nasÄ±l yapÄ±lÄ±r?",
        assistant_response="TÃ¼rk kahvesi iÃ§in ince Ã§ekilmiÅŸ kahve, su ve isteÄŸe gÃ¶re ÅŸeker kullanÄ±lÄ±r...",
        intent="turkish_culture"
    )
    
    # Arama testi
    print("\nğŸ” Arama: 'Python liste'")
    results = handler.search("Python liste", top_k=2)
    for r in results:
        print(f"  [{r['similarity']:.0%}] {r['text'][:100]}...")
    
    print("\nğŸ” Arama: 'kahve'")
    results = handler.search("kahve", top_k=2)
    for r in results:
        print(f"  [{r['similarity']:.0%}] {r['text'][:100]}...")
    
    print("\nğŸ” Arama: 'adÄ±m ne'")
    results = handler.search("benim adÄ±m ne", top_k=2)
    for r in results:
        print(f"  [{r['similarity']:.0%}] {r['text'][:100]}...")
    
    # Context testi
    print("\nğŸ“š RAG Context iÃ§in 'Python sÄ±ralama':")
    context = handler.get_relevant_context("Python sÄ±ralama")
    print(context)
    
    # Ä°statistikler
    print("\nğŸ“Š Ä°statistikler:")
    stats = handler.get_stats()
    print(f"  Toplam belge: {stats['total_documents']}")
    print(f"  Embedding boyutu: {stats['embedding_dim']}")
    if 'type_distribution' in stats:
        print(f"  Tip daÄŸÄ±lÄ±mÄ±: {stats['type_distribution']}")
    
    # Temizlik
    handler.clear_all()
    print("\nâœ… Test tamamlandÄ±!")

#!/usr/bin/env python3
"""
EVO-TR: Feedback Ä°ÅŸleme ve Lifecycle BaÅŸlatÄ±cÄ±

Bu script feedback veritabanÄ±ndaki verileri analiz eder ve
gerektiÄŸinde incremental training baÅŸlatÄ±r.

KullanÄ±m:
    python scripts/process_feedback.py --analyze    # Sadece analiz
    python scripts/process_feedback.py --train      # EÄŸitim baÅŸlat
    python scripts/process_feedback.py --stats      # Ä°statistikler
"""

import sys
sys.path.insert(0, ".")

import argparse
from datetime import datetime
from pathlib import Path
from rich.console import Console
from rich.table import Table

from src.lifecycle.feedback import FeedbackDatabase
from src.lifecycle.preference_learning import PreferenceCollector, PreferenceLearningPipeline


console = Console()


def show_stats():
    """Feedback istatistiklerini gÃ¶ster."""
    db = FeedbackDatabase("./data/feedback.db")
    
    # Genel istatistikler
    stats = db.get_stats()
    
    table = Table(title="ğŸ“Š Feedback Ä°statistikleri")
    table.add_column("Metrik", style="cyan")
    table.add_column("DeÄŸer", style="white")
    
    table.add_row("Toplam Feedback", str(stats.get("total", 0)))
    table.add_row("ğŸ‘ Pozitif (thumbs_up)", str(stats.get("thumbs_up", 0)))
    table.add_row("ğŸ‘ Negatif (thumbs_down)", str(stats.get("thumbs_down", 0)))
    table.add_row("âœï¸ DÃ¼zeltme (edit)", str(stats.get("edit", 0)))
    table.add_row("Ä°ÅŸlenmemiÅŸ", str(stats.get("unprocessed", 0)))
    table.add_row("EÄŸitimde KullanÄ±lmayan", str(stats.get("unused_for_training", 0)))
    
    console.print(table)
    
    # DÃ¼zeltmeleri gÃ¶ster
    corrections = db.get_corrected_responses(limit=10)
    if corrections:
        console.print(f"\n[green]âœï¸ Son {len(corrections)} DÃ¼zeltme:[/green]")
        for i, entry in enumerate(corrections, 1):
            console.print(f"\n[dim]{i}. {entry.timestamp}[/dim] [{entry.adapter_used}]")
            console.print(f"   [cyan]Soru:[/cyan] {entry.user_message[:80]}...")
            console.print(f"   [red]YanlÄ±ÅŸ:[/red] {entry.assistant_response[:80]}...")
            console.print(f"   [green]DoÄŸru:[/green] {entry.corrected_response[:80]}...")


def analyze_feedback():
    """Feedback'leri analiz et ve eÄŸitim iÃ§in hazÄ±r olanlarÄ± gÃ¶ster."""
    db = FeedbackDatabase("./data/feedback.db")
    
    # DÃ¼zeltilmiÅŸ yanÄ±tlar (en deÄŸerli)
    corrections = db.get_corrected_responses(limit=100)
    console.print(f"\n[green]âœï¸ EÄŸitime HazÄ±r DÃ¼zeltme: {len(corrections)} adet[/green]")
    
    # Negatif feedback'ler
    negatives = db.get_negative_feedback(limit=100)
    console.print(f"[yellow]ğŸ‘ Negatif Feedback: {len(negatives)} adet[/yellow]")
    
    # Ä°ÅŸlenmemiÅŸ feedback'ler
    unprocessed = db.get_unprocessed_feedback(limit=100)
    console.print(f"[cyan]ğŸ“‹ Ä°ÅŸlenmemiÅŸ: {len(unprocessed)} adet[/cyan]")
    
    # EÄŸitim iÃ§in yeterli veri var mÄ±?
    min_corrections_for_training = 10
    if len(corrections) >= min_corrections_for_training:
        console.print(f"\n[bold green]âœ… Yeterli dÃ¼zeltme var! EÄŸitim baÅŸlatÄ±labilir.[/bold green]")
        console.print(f"[dim]   Komut: python scripts/process_feedback.py --train[/dim]")
    else:
        needed = min_corrections_for_training - len(corrections)
        console.print(f"\n[yellow]âš ï¸ EÄŸitim iÃ§in {needed} dÃ¼zeltme daha gerekli.[/yellow]")
        console.print(f"[dim]   CLI'da /correct komutu ile dÃ¼zeltme yapabilirsiniz.[/dim]")
    
    return {
        "corrections": len(corrections),
        "negatives": len(negatives),
        "unprocessed": len(unprocessed),
        "ready_for_training": len(corrections) >= min_corrections_for_training
    }


def prepare_training_data():
    """Feedback'lerden DPO eÄŸitim verisi hazÄ±rla."""
    db = FeedbackDatabase("./data/feedback.db")
    collector = PreferenceCollector(storage_path="./data/preferences")
    
    # DÃ¼zeltmeleri al
    corrections = db.get_corrected_responses(limit=100)
    
    if not corrections:
        console.print("[yellow]âš ï¸ DÃ¼zeltilmiÅŸ yanÄ±t bulunamadÄ±.[/yellow]")
        return None
    
    console.print(f"[cyan]ğŸ“‹ {len(corrections)} dÃ¼zeltme iÅŸleniyor...[/cyan]")
    
    # Preference pair'ler oluÅŸtur
    pairs = []
    for entry in corrections:
        pair = collector.create_from_feedback(
            prompt=entry.user_message,
            response=entry.assistant_response,
            feedback_type="edit",
            adapter=entry.adapter_used,
            corrected_response=entry.corrected_response
        )
        if pair:
            pairs.append(pair)
    
    console.print(f"[green]âœ… {len(pairs)} preference pair oluÅŸturuldu.[/green]")
    
    # DPO formatÄ±nda kaydet
    if pairs:
        collector.save()
        dpo_data = collector.export_for_dpo()
        
        output_dir = Path("./data/training/dpo_from_feedback")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        output_file = output_dir / f"dpo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
        
        import json
        with open(output_file, "w", encoding="utf-8") as f:
            for item in dpo_data:
                f.write(json.dumps(item, ensure_ascii=False) + "\n")
        
        console.print(f"[green]âœ… DPO verisi kaydedildi: {output_file}[/green]")
        
        # Feedback'leri iÅŸlenmiÅŸ olarak iÅŸaretle
        feedback_ids = [entry.id for entry in corrections if entry.id]
        db.mark_as_used_for_training(feedback_ids)
        console.print(f"[dim]   {len(feedback_ids)} feedback eÄŸitimde kullanÄ±ldÄ± olarak iÅŸaretlendi.[/dim]")
        
        return output_file
    
    return None


def run_incremental_training(dpo_file: Path):
    """DPO verisi ile incremental training baÅŸlat."""
    console.print(f"\n[yellow]ğŸš€ Incremental Training baÅŸlatÄ±lÄ±yor...[/yellow]")
    console.print(f"[dim]   Veri: {dpo_file}[/dim]")
    
    # TODO: mlx_lm DPO training entegrasyonu
    # Åimdilik sadece mesaj yazdÄ±r
    console.print("[yellow]âš ï¸ DPO training henÃ¼z entegre edilmedi.[/yellow]")
    console.print("[dim]   Manuel olarak ÅŸu komutu Ã§alÄ±ÅŸtÄ±rabilirsiniz:[/dim]")
    console.print(f"[dim]   mlx_lm.lora --data {dpo_file.parent} --model models/base/qwen-2.5-3b-instruct[/dim]")


def main():
    parser = argparse.ArgumentParser(description="EVO-TR Feedback Ä°ÅŸleme")
    parser.add_argument("--stats", action="store_true", help="Ä°statistikleri gÃ¶ster")
    parser.add_argument("--analyze", action="store_true", help="Feedback'leri analiz et")
    parser.add_argument("--train", action="store_true", help="EÄŸitim verisi hazÄ±rla ve baÅŸlat")
    
    args = parser.parse_args()
    
    console.print("\n[bold blue]ğŸ”„ EVO-TR Feedback Ä°ÅŸleyici[/bold blue]\n")
    
    if args.stats:
        show_stats()
    elif args.analyze:
        analyze_feedback()
    elif args.train:
        analysis = analyze_feedback()
        if analysis["ready_for_training"]:
            dpo_file = prepare_training_data()
            if dpo_file:
                run_incremental_training(dpo_file)
        else:
            console.print("[yellow]âš ï¸ EÄŸitim iÃ§in yeterli veri yok.[/yellow]")
    else:
        # VarsayÄ±lan: stats + analyze
        show_stats()
        console.print()
        analyze_feedback()


if __name__ == "__main__":
    main()

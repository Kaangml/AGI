# ğŸš€ EVO-TR: Master Todo List (Mac Mini M4 Edition)

**Tarih:** 02 AralÄ±k 2025  
**DonanÄ±m:** Mac Mini M4 (Apple Silicon)  
**Durum:** PoC (Proof of Concept)

---

## ğŸ“‹ Genel BakÄ±ÅŸ

| Faz | Ä°sim | Durum | Tahmini SÃ¼re |
|-----|------|-------|--------------|
| 0 | AltyapÄ± ve Kurulum | âœ… TamamlandÄ± | 1-2 gÃ¼n |
| 1 | Router (YÃ¶nlendirici) | âœ… TamamlandÄ± | 2-3 gÃ¼n |
| 2 | TÃ¼rkÃ§e Uzman (LoRA #1) | âœ… TamamlandÄ± | 3-4 gÃ¼n |
| 3 | Python Uzman (LoRA #2) | âœ… TamamlandÄ± | 2-3 gÃ¼n |
| 4 | HafÄ±za ve RAG | âœ… TamamlandÄ± | 2-3 gÃ¼n |
| 5 | Entegrasyon | âœ… TamamlandÄ± | 2-3 gÃ¼n |
| 6 | YaÅŸam DÃ¶ngÃ¼sÃ¼ | âœ… TamamlandÄ± | 2-3 gÃ¼n |

### ğŸ‰ TÃœM FAZLAR TAMAMLANDI!

**Toplam Test SayÄ±sÄ±:** 15 (Router) + 25 (Memory) + 25 (Integration) + 28 (Lifecycle) = **93 test geÃ§ti!**

---

## â¬œ Faz 0: AltyapÄ± ve Kurulum (The Skeleton)

*AmaÃ§: Mac M4 Ã¼zerinde Ã§alÄ±ÅŸacak temel ortamÄ± hazÄ±rlamak*

### 0.1 Sistem Gereksinimleri KontrolÃ¼
- [ ] macOS sÃ¼rÃ¼mÃ¼ kontrolÃ¼ (Sonoma 14+ Ã¶nerilir)
- [ ] Python 3.10+ kurulu mu kontrol et
- [ ] Xcode Command Line Tools kurulu mu kontrol et
- [ ] Homebrew kurulu mu kontrol et

### 0.2 Python OrtamÄ± Kurulumu
- [ ] Proje dizininde virtual environment oluÅŸtur
  ```bash
  python3 -m venv .venv
  source .venv/bin/activate
  ```
- [ ] pip gÃ¼ncelle
- [ ] requirements.txt oluÅŸtur

### 0.3 Temel BaÄŸÄ±mlÄ±lÄ±klar
- [ ] `mlx` kurulumu (Apple ML Framework)
- [ ] `mlx-lm` kurulumu (LLM desteÄŸi)
- [ ] `transformers` kurulumu
- [ ] `huggingface_hub` kurulumu
- [ ] `torch` kurulumu (CPU-only, MLX ile uyumluluk iÃ§in)

### 0.4 Hugging Face AyarlarÄ±
- [ ] `.env` dosyasÄ±nda HF_TOKEN kontrolÃ¼
- [ ] `huggingface-cli login` ile giriÅŸ yap
- [ ] Token'Ä± test et: Model eriÅŸimi var mÄ±?

### 0.5 Base Model Ä°ndirme
- [ ] Qwen-2.5-3B-Instruct MLX formatÄ±nda indir
  ```bash
  mlx_lm.convert --hf-path Qwen/Qwen2.5-3B-Instruct --mlx-path ./models/qwen-2.5-3b-instruct -q
  ```
- [ ] Model boyutunu kontrol et (~2GB olmalÄ±)
- [ ] "Hello World" testi yap

### 0.6 Dizin YapÄ±sÄ± OluÅŸturma
- [ ] `src/` ana kaynak dizini
- [ ] `models/` model dizini
- [ ] `adapters/` LoRA adaptÃ¶r dizini
- [ ] `data/` veri dizini
- [ ] `logs/` log dizini
- [ ] `scripts/` yardÄ±mcÄ± script dizini

---

## â¬œ Faz 1: Router (YÃ¶nlendirici Zeka)

*AmaÃ§: Gelen sorunun hangi uzmana gitmesi gerektiÄŸine karar veren "KapÄ± GÃ¶revlisi"*

### 1.1 Intent Veri Seti HazÄ±rlama
- [ ] Intent kategorilerini belirle:
  - `general_chat` - Genel sohbet, selamlaÅŸma
  - `turkish_culture` - TÃ¼rkÃ§e kÃ¼ltÃ¼r, deyimler
  - `code_python` - Python kodu yazma
  - `code_debug` - Hata ayÄ±klama
  - `memory_recall` - GeÃ§miÅŸi hatÄ±rlama
- [ ] Her kategori iÃ§in 20+ Ã¶rnek yaz
- [ ] `data/intents/intent_dataset.json` oluÅŸtur
- [ ] Veri setini train/val olarak bÃ¶l (80/20)

### 1.2 SÄ±nÄ±flandÄ±rÄ±cÄ± Model SeÃ§imi
- [ ] `distilbert-base-multilingual-cased` indir
- [ ] Alternatif: `sentence-transformers` + cosine similarity
- [ ] Bellek kullanÄ±mÄ± test et (<500MB olmalÄ±)

### 1.3 Router EÄŸitimi
- [ ] `src/router/train_classifier.py` yaz
- [ ] Few-shot learning veya fine-tuning seÃ§
- [ ] EÄŸitimi baÅŸlat
- [ ] Accuracy kontrolÃ¼ (%90+ hedef)
- [ ] Model'i kaydet: `models/router/`

### 1.4 Router API YazÄ±mÄ±
- [ ] `src/router/classifier.py` oluÅŸtur
- [ ] `RouterClassifier` sÄ±nÄ±fÄ± yaz
- [ ] `predict(text) -> {"intent": str, "confidence": float}` metodu
- [ ] Confidence threshold ayarla (0.7 Ã¶nerilen)
- [ ] DÃ¼ÅŸÃ¼k confidence iÃ§in fallback stratejisi

### 1.5 Router Testleri
- [ ] `tests/test_router.py` yaz
- [ ] Edge case'leri test et
- [ ] Latency testi (<50ms hedef)

---

## â¬œ Faz 2: TÃ¼rkÃ§e Uzman (LoRA #1)

*AmaÃ§: Base modelin TÃ¼rkÃ§e iletiÅŸim yeteneklerini geliÅŸtirmek*

### 2.1 Veri Seti HazÄ±rlama
- [ ] `CohereForAI/aya_dataset` TÃ¼rkÃ§e subset'ini indir
- [ ] `Turkish-Instructions` veri setini incele
- [ ] Veri setlerini birleÅŸtir
- [ ] Temizlik yap:
  - Duplice kayÄ±tlarÄ± kaldÄ±r
  - Ã‡ok kÄ±sa/uzun Ã¶rnekleri filtrele
  - Format kontrolÃ¼
- [ ] Alpaca formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r:
  ```json
  {"instruction": "...", "input": "...", "output": "..."}
  ```
- [ ] `data/training/tr_chat_dataset.jsonl` oluÅŸtur

### 2.2 QLoRA EÄŸitim KonfigÃ¼rasyonu
- [ ] `scripts/train_lora_tr.py` oluÅŸtur
- [ ] MLX LoRA parametreleri:
  ```python
  lora_config = {
      "r": 8,                    # LoRA rank
      "lora_alpha": 16,          # Scaling factor
      "lora_dropout": 0.05,
      "target_modules": ["q_proj", "v_proj"]
  }
  ```
- [ ] Training parametreleri:
  ```python
  training_args = {
      "learning_rate": 1e-4,
      "batch_size": 1,           # M4 iÃ§in gÃ¼venli
      "epochs": 3,
      "gradient_accumulation": 4
  }
  ```

### 2.3 EÄŸitim SÃ¼reci
- [ ] EÄŸitimi baÅŸlat
- [ ] Loss deÄŸerlerini logla
- [ ] Checkpoint'ler kaydet (her epoch)
- [ ] EÄŸitim bitince final model kaydet
- [ ] `adapters/adapter_tr_chat/` dizinine taÅŸÄ±

### 2.4 TÃ¼rkÃ§e Adapter Testi
- [ ] Base + Adapter yÃ¼kle
- [ ] Test promptlarÄ± hazÄ±rla:
  - SelamlaÅŸma
  - GÃ¼nlÃ¼k sohbet
  - TÃ¼rk kÃ¼ltÃ¼rÃ¼ sorularÄ±
  - Deyim/atasÃ¶zÃ¼ aÃ§Ä±klamalarÄ±
- [ ] YanÄ±t kalitesini deÄŸerlendir
- [ ] Base model ile karÅŸÄ±laÅŸtÄ±r

---

## âœ… Faz 3: Python Uzman (LoRA #2) - TAMAMLANDI!

*AmaÃ§: Kod yazma ve debugging yeteneklerini geliÅŸtirmek*

### âœ… 3.1 Veri Seti HazÄ±rlama
- [x] `openai/humaneval` indir (164 Ã¶rnek)
- [x] `mbpp` (Mostly Basic Programming Problems) indir (964 Ã¶rnek)
- [x] `sahil2801/CodeAlpaca-20k` indir (9208 Ã¶rnek)
- [x] `iamtarun/code_instructions_120k_alpaca` indir (5000 Ã¶rnek)
- [x] Manuel Ã¶rnekler (58 Ã¶rnek)
- [x] Veriler temizlendi: 15390 â†’ 13334 geÃ§erli Ã¶rnek
- [x] `data/training/python_coder_mlx/train.jsonl` (12,000 Ã¶rnek)
- [x] `data/training/python_coder_mlx/valid.jsonl` (1,334 Ã¶rnek)

### âœ… 3.2 QLoRA EÄŸitim KonfigÃ¼rasyonu
- [x] `configs/lora_python_config.yaml` oluÅŸturuldu
- [x] LoRA: rank=16, alpha=32, num_layers=16
- [x] Training: lr=1e-5, iters=3000, batch=2, max_seq=512

### âœ… 3.3 EÄŸitim SÃ¼reci
- [x] EÄŸitim tamamlandÄ± (3000 iterasyon)
- [x] En iyi val_loss: 0.551 (iter 2800)
- [x] Final val_loss: 0.634
- [x] Peak memory: 6.64 GB
- [x] `adapters/python_coder/adapters.safetensors` kaydedildi

### âœ… 3.4 Python Adapter Testi
- [x] is_prime() - âœ… doÄŸru
- [x] binary_search() - âœ… doÄŸru
- [x] fibonacci() (TÃ¼rkÃ§e prompt) - âœ… doÄŸru
- [x] Bug fix (a-b â†’ a+b) - âœ… doÄŸru
- [ ] Algoritma implementasyonu
- [ ] Bug fixing senaryolarÄ±
- [ ] Kod aÃ§Ä±klama yetenekleri

---

## âœ… Faz 4: HafÄ±za ve RAG Sistemi - TAMAMLANDI!

*AmaÃ§: SÃ¼rekli hatÄ±rlayan bir sistem oluÅŸturmak*

### âœ… 4.1 ChromaDB Kurulumu
- [x] `chromadb` paketini kur (1.3.5)
- [x] Persistent storage ayarla
- [x] `data/chromadb/` dizini oluÅŸtur
- [x] Connection testi yap

### âœ… 4.2 Embedding Model Entegrasyonu
- [x] `paraphrase-multilingual-MiniLM-L12-v2` kullanÄ±ldÄ± (TÃ¼rkÃ§e destekli)
- [x] Embedding boyutu: 384 dimension
- [x] TÃ¼rkÃ§e benzerlik testi: %82 ("Merhaba" vs "Selam")

### âœ… 4.3 ChromaDB Handler
- [x] `src/memory/chromadb_handler.py` oluÅŸtur
- [x] `MemoryHandler` sÄ±nÄ±fÄ±:
  - `add_memory(text, metadata)`
  - `add_conversation(user, assistant, intent)`
  - `search(query, top_k, memory_type)`
  - `get_relevant_context(query)` - RAG iÃ§in
  - `delete(id)`, `clear_all()`
  - `get_stats()`

### âœ… 4.4 KÄ±sa SÃ¼reli HafÄ±za
- [x] `src/memory/context_buffer.py` oluÅŸtur
- [x] Son N mesajÄ± tutan buffer
- [x] Token limiti kontrolÃ¼
- [x] Sliding window mantÄ±ÄŸÄ±
- [x] Chat format export

### âœ… 4.5 Unified Memory Manager
- [x] `src/memory/memory_manager.py` oluÅŸtur
- [x] KÄ±sa + Uzun sÃ¼reli hafÄ±za birleÅŸimi
- [x] Auto-save Ã¶zelliÄŸi
- [x] RAG context oluÅŸturma

### âœ… 4.6 Unit Testler
- [x] `tests/test_memory.py` - **25/25 test geÃ§ti**

### âœ… 4.7 Demo
- [x] `scripts/memory_rag_demo.py` - LLM entegrasyonu demo

---

## âœ… Faz 5: Sistem Entegrasyonu - TAMAMLANDI!

*AmaÃ§: TÃ¼m parÃ§alarÄ± birleÅŸtirmek*

### âœ… 5.1 LoRA Manager
- [x] `src/experts/lora_manager.py` oluÅŸturuldu
- [x] Adapter yÃ¼kleme/deÄŸiÅŸtirme
- [x] Adapter caching (yÃ¼klenen adapterlar Ã¶nbelleÄŸe alÄ±nÄ±r)
- [x] Hot-swap desteÄŸi
- [x] Intent bazlÄ± adapter seÃ§imi

### âœ… 5.2 Inference Engine
- [x] `src/inference/mlx_inference.py` oluÅŸturuldu
- [x] MLX-LM ile generation
- [x] Chat template formatting
- [x] Intent-based system prompts
- [x] Token limiti yÃ¶netimi

### âœ… 5.3 Ana Orkestrasyon
- [x] `src/orchestrator.py` oluÅŸturuldu (EvoTR sÄ±nÄ±fÄ±)
- [x] Flow:
  ```
  1. User Input
  2. Router -> Intent Classification
  3. LoRA Manager -> Load Adapter
  4. Memory -> Retrieve Context
  5. Inference -> Generate Response
  6. Memory -> Save Conversation
  ```
- [x] Error handling
- [x] Metodlar: chat(), get_status(), clear_conversation(), add_fact(), search_memory()

### âœ… 5.4 CLI Interface
- [x] `scripts/chat_cli.py` oluÅŸturuldu
- [x] `/help`, `/status`, `/clear`, `/adapters`, `/memory`, `/quit` komutlarÄ±
- [x] Renkli terminal Ã§Ä±ktÄ±sÄ±
- [x] Interaktif sohbet deneyimi

### âœ… 5.5 Entegrasyon Testleri
- [x] `tests/test_integration.py` - **25/25 test geÃ§ti!**
- [x] Test SÄ±nÄ±flarÄ±:
  - TestRouterIntegration: 5/5 âœ…
  - TestMemoryIntegration: 3/3 âœ…
  - TestLoRAIntegration: 3/3 âœ…
  - TestInferenceIntegration: 3/3 âœ…
  - TestOrchestratorIntegration: 7/7 âœ…
  - TestEndToEndFlow: 2/2 âœ…
  - TestPerformance: 2/2 âœ…
- [x] TÃ¼rkÃ§e sohbet -> Kod yazma geÃ§iÅŸi
- [x] HafÄ±za hatÄ±rlama
- [x] Performance metrikleri (response time < 5s)

---

## âœ… Faz 6: YaÅŸam DÃ¶ngÃ¼sÃ¼ (Sync/Async) - TAMAMLANDI!

*AmaÃ§: Sistemin kendi kendini gÃ¼ncellemesi*

### âœ… 6.1 Loglama Sistemi
- [x] `src/lifecycle/logger.py` oluÅŸturuldu
- [x] Structured logging (JSON format)
- [x] Log rotasyonu (gÃ¼nlÃ¼k dosyalar)
- [x] Conversation, performance, error tracking
- [x] Session management

### âœ… 6.2 GÃ¼ndÃ¼z Modu (Sync Handler)
- [x] `src/lifecycle/sync_handler.py` oluÅŸturuldu
- [x] Real-time chat loop
- [x] Session state management
- [x] Error handling & callbacks
- [x] Graceful shutdown

### âœ… 6.3 Gece Modu (Async Processor)
- [x] `src/lifecycle/async_processor.py` oluÅŸturuldu
- [x] GÃ¼nlÃ¼k log analizi
- [x] BaÅŸarÄ±sÄ±z yanÄ±t tespiti
- [x] Pattern/trend detection
- [x] Bilgi Ã§Ä±karÄ±mÄ± (facts extraction)
- [x] ChromaDB'ye bilgi yazÄ±mÄ±

### âœ… 6.4 Scheduler
- [x] `scripts/run_analysis.py` oluÅŸturuldu
- [x] `configs/com.evotr.night-analysis.plist` (LaunchD)
- [x] Manuel tetikleme seÃ§eneÄŸi
- [x] Gece 03:00 otomatik Ã§alÄ±ÅŸtÄ±rma

### âœ… 6.5 Self-Improvement Pipeline
- [x] `src/lifecycle/self_improvement.py` oluÅŸturuldu
- [x] Performans metrik izleme
- [x] Re-training trigger'larÄ±
- [x] Ä°yileÅŸtirme gÃ¶rev yÃ¶netimi
- [x] Otomatik rapor oluÅŸturma

### âœ… 6.6 Unit Tests
- [x] `tests/test_lifecycle.py` - **28/28 test geÃ§ti!**

---

## ğŸ“ Notlar

### Bellek YÃ¶netimi Ä°puÃ§larÄ± (Mac M4)
- Batch size=1 kullan, memory overflow Ã¶nle
- Gradient checkpointing aktif et
- Model'leri lazy load yap
- KullanÄ±lmayan adapter'larÄ± unload et

### Performans Hedefleri
- Router latency: <50ms
- Inference latency: <500ms (ilk token)
- Memory search: <100ms
- Token/saniye: 30+ (streaming)

### Debugging
- `MPS_FALLBACK_TO_CPU=1` (fallback iÃ§in)
- `PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0` (memory)

---

## ğŸ”— FaydalÄ± Linkler

- [MLX Documentation](https://ml-explore.github.io/mlx/)
- [MLX-LM Examples](https://github.com/ml-explore/mlx-examples)
- [Qwen2.5 Model Card](https://huggingface.co/Qwen/Qwen2.5-3B-Instruct)
- [ChromaDB Docs](https://docs.trychroma.com/)
- [HuggingFace Hub](https://huggingface.co/)

---

*Bu liste projemizin yol haritasÄ±dÄ±r. Her tamamlanan gÃ¶rev iÃ§in â¬œ yerine âœ… koyun.*

---

# ğŸš€ GELECEK FAZLAR: AGI'ya Giden Yol

**Tarih:** 04 AralÄ±k 2025  
**Mevcut Durum:** v1.0 (PoC TamamlandÄ± - 93 test)  
**Felsefe:** Bebek ğŸ¼ â†’ Ã‡ocuk ğŸ§’ â†’ Uzman ğŸ“ â†’ Usta ğŸ§™â€â™‚ï¸

---

## ğŸ“‹ Gelecek Fazlar Genel BakÄ±ÅŸ

| Faz | Ä°sim | Durum | Ã–ncelik | Tahmini SÃ¼re |
|-----|------|-------|---------|--------------|
| 7 | GeliÅŸmiÅŸ Uzmanlar | â¬œ Bekliyor | P1 | 3-4 gÃ¼n |
| 8 | Web ArayÃ¼zÃ¼ | â¬œ Bekliyor | P2 | 4-5 gÃ¼n |
| 9 | Continuous Learning | â¬œ Bekliyor | P1 | 5-7 gÃ¼n |
| 10 | Test-Time Training | â¬œ Bekliyor | P2 | 7-10 gÃ¼n |
| 11 | Multi-Modal | â¬œ Bekliyor | P3 | 10-14 gÃ¼n |
| 12 | Meta-Learning | â¬œ Bekliyor | P3 | 14+ gÃ¼n |

---

## ğŸ”„ Faz 7: GeliÅŸmiÅŸ Uzmanlar (More Experts)

*AmaÃ§: Yeni domain-specific LoRA adaptÃ¶rleri eklemek*

### 7.1 Matematik UzmanÄ± (LoRA #3) - **TAMAMLANDI** âœ…
- [x] Matematik veri seti hazÄ±rla (GSM8K, MATH) âœ… 8,792 Ã¶rnek
- [x] TÃ¼rkÃ§e matematik problemleri ekle âœ… 48 Ã¶rnek
- [x] Train/Val split oluÅŸtur âœ… 6,768/753
- [x] Router'a `code_math` intent ekle âœ…
- [x] Unit testler yaz âœ… 22 test
- [x] LoRA Manager'a math_expert ekle âœ…
- [x] Inference'a code_math system prompt ekle âœ…
- [x] `adapters/math_expert/` LoRA eÄŸit âœ… **1500 iter, Val Loss: 0.512**
- [x] Entegrasyon testi âœ… **116/116 passed**

**SonuÃ§lar:**
- **Val Loss:** 1.969 â†’ 0.512 (74% iyileÅŸme)
- **Training Time:** ~60 dakika
- **Peak Memory:** 7.2 GB
- **Adapter Size:** 26.6 MB

**HazÄ±rlanan Dosyalar:**
```
scripts/download_gsm8k.py      # GSM8K indirici
scripts/prepare_math_data.py   # Veri birleÅŸtirici
data/training/math/            # TÃ¼m matematik verileri
configs/lora_math_config.yaml  # LoRA konfigÃ¼rasyonu
tests/test_math_expert.py      # 22 test
adapters/math_expert/          # EÄŸitilmiÅŸ adapter âœ…
```

### 7.2 Bilim UzmanÄ± (LoRA #4)
- [ ] Bilim veri seti hazÄ±rla (fizik, kimya, biyoloji)
- [ ] TÃ¼rkÃ§e bilim iÃ§erikleri topla
- [ ] `adapters/science_expert/` LoRA eÄŸit
- [ ] Router'a `science_*` intent ekle
- [ ] Unit testler yaz

### 7.3 Tarih/KÃ¼ltÃ¼r UzmanÄ± (LoRA #5)
- [ ] TÃ¼rk tarihi veri seti hazÄ±rla
- [ ] OsmanlÄ±, Cumhuriyet dÃ¶nemi iÃ§erikleri
- [ ] `adapters/history_expert/` LoRA eÄŸit
- [ ] Router'a `history_culture` intent ekle
- [ ] Unit testler yaz

### 7.4 Adapter Versiyonlama
- [ ] Adapter metadata schema tasarla
- [ ] Version tracking sistemi
- [ ] A/B testing altyapÄ±sÄ±
- [ ] Rollback mekanizmasÄ±

---

## â¬œ Faz 8: Web ArayÃ¼zÃ¼ (The Interface)

*AmaÃ§: KullanÄ±cÄ± dostu web arayÃ¼zÃ¼ oluÅŸturmak*

### 8.1 Backend API (FastAPI)
- [ ] FastAPI proje yapÄ±sÄ± oluÅŸtur
- [ ] `/chat` endpoint (streaming)
- [ ] `/memory` endpoint (RAG search)
- [ ] `/status` endpoint (sistem durumu)
- [ ] `/adapters` endpoint (adapter listesi)
- [ ] WebSocket desteÄŸi
- [ ] Rate limiting

### 8.2 Frontend (React/Next.js)
- [ ] Next.js proje yapÄ±sÄ±
- [ ] Chat UI komponenti
- [ ] Streaming response gÃ¶rÃ¼ntÃ¼leme
- [ ] Adapter seÃ§ici
- [ ] KonuÅŸma geÃ§miÅŸi
- [ ] Dark/Light mode

### 8.3 Deployment
- [ ] Docker containerization
- [ ] docker-compose.yml
- [ ] Local serving script
- [ ] SSL/TLS ayarlarÄ±

---

## â¬œ Faz 9: Continuous Learning (SÃ¼rekli Ã–ÄŸrenme)

*AmaÃ§: KullanÄ±cÄ± etkileÅŸimlerinden sÃ¼rekli Ã¶ÄŸrenen sistem*

### 9.1 Feedback Collection
- [ ] KullanÄ±cÄ± geri bildirim UI (ğŸ‘/ğŸ‘)
- [ ] Implicit feedback tracking (edit, retry)
- [ ] Feedback database schema
- [ ] Geri bildirim analizi pipeline

### 9.2 Active Learning
- [ ] Uncertainty detection (dÃ¼ÅŸÃ¼k gÃ¼ven yanÄ±tlarÄ±)
- [ ] Yeni eÄŸitim verisi seÃ§imi
- [ ] Human-in-the-loop workflow
- [ ] Annotation arayÃ¼zÃ¼

### 9.3 Incremental Training
- [ ] Online LoRA gÃ¼ncelleme stratejisi
- [ ] Catastrophic forgetting Ã¶nleme (EWC, SI)
- [ ] Checkpoint yÃ¶netimi
- [ ] A/B test ile validasyon

### 9.4 Preference Learning (RLHF-lite)
- [ ] Preference data collection
- [ ] DPO (Direct Preference Optimization) implementasyonu
- [ ] Reward model eÄŸitimi
- [ ] PPO/REINFORCE alternatifleri araÅŸtÄ±r

---

## â¬œ Faz 10: Test-Time Training (TTT)

*AmaÃ§: Inference sÄ±rasÄ±nda anlÄ±k adaptasyon*

### 10.1 TTT AraÅŸtÄ±rma
- [ ] TTT paper'larÄ±nÄ± incele (TTT-LLM, etc.)
- [ ] MLX uyumluluÄŸu araÅŸtÄ±r
- [ ] Memory/compute trade-off analizi
- [ ] Prototype implementasyon

### 10.2 Context-Aware Adaptation
- [ ] Context encoding stratejisi
- [ ] Gradient-based adaptation (anlÄ±k)
- [ ] Cache mekanizmasÄ±
- [ ] Latency optimizasyonu

### 10.3 Few-Shot Enhancement
- [ ] In-context learning iyileÅŸtirme
- [ ] Retrieval-augmented few-shot
- [ ] Example selection stratejisi
- [ ] Dynamic prompting

### 10.4 Self-Correction
- [ ] Ã‡Ä±ktÄ± kalite deÄŸerlendirme
- [ ] Otomatik dÃ¼zeltme loop
- [ ] Consistency checking
- [ ] Confidence calibration

---

## â¬œ Faz 11: Multi-Modal Yetenekler

*AmaÃ§: GÃ¶rÃ¼ntÃ¼, ses ve diÄŸer modaliteleri desteklemek*

### 11.1 Vision Capability
- [ ] Vision model araÅŸtÄ±rmasÄ± (LLaVA, Qwen-VL)
- [ ] MLX uyumlu vision encoder
- [ ] `adapters/vision_expert/` LoRA
- [ ] GÃ¶rÃ¼ntÃ¼ anlama testleri
- [ ] OCR entegrasyonu

### 11.2 Audio Capability
- [ ] Whisper entegrasyonu (speech-to-text)
- [ ] TTS entegrasyonu (text-to-speech)
- [ ] `adapters/audio_expert/` LoRA
- [ ] Sesli sohbet modu

### 11.3 Code Visualization
- [ ] Kod diagram Ã¼retimi (Mermaid, PlantUML)
- [ ] Execution trace visualization
- [ ] Debugging visual aids
- [ ] Interactive code exploration

---

## â¬œ Faz 12: Meta-Learning (Learning to Learn)

*AmaÃ§: Yeni gÃ¶revlere hÄ±zlÄ± adaptasyon yeteneÄŸi*

### 12.1 Meta-Learning Framework
- [ ] MAML/Reptile araÅŸtÄ±rmasÄ±
- [ ] Task distribution tanÄ±mÄ±
- [ ] Meta-training loop
- [ ] Few-shot evaluation

### 12.2 Self-Directed Learning
- [ ] Eksik bilgi tespiti (knowledge gaps)
- [ ] Otomatik veri toplama stratejisi
- [ ] Web scraping pipeline
- [ ] Knowledge verification

### 12.3 Skill Composition
- [ ] LoRA composition (merging strategies)
- [ ] Dynamic expert routing
- [ ] Skill transfer mekanizmasÄ±
- [ ] Emergent capabilities tracking

### 12.4 Otonom AraÅŸtÄ±rma
- [ ] Paper reading pipeline
- [ ] Knowledge synthesis
- [ ] Experiment design
- [ ] Self-benchmark

---

## ğŸ§ª AraÅŸtÄ±rma KonularÄ± (Research Backlog)

### R1. Symbolic + Neural Hibrit
- [ ] Knowledge graph entegrasyonu
- [ ] Logical reasoning module
- [ ] Causal inference
- [ ] Neuro-symbolic architecture

### R2. Efficiency Optimizations
- [ ] Model pruning
- [ ] Knowledge distillation
- [ ] Speculative decoding
- [ ] KV-cache optimization

### R3. Safety & Alignment
- [ ] Constitutional AI principles
- [ ] Self-improvement guardrails
- [ ] Value alignment
- [ ] Interpretability tools

### R4. Distributed Learning
- [ ] Federated learning setup
- [ ] Multi-device coordination
- [ ] Privacy-preserving training
- [ ] Edge deployment optimization

---

## ğŸ“Š Metrikler ve BaÅŸarÄ± Kriterleri

### Faz 7-8 (KÄ±sa Vade)
- [ ] 3+ yeni uzman LoRA
- [ ] Web UI ile 10+ kullanÄ±cÄ± testi
- [ ] Response latency < 1s
- [ ] Uptime %99+

### Faz 9-10 (Orta Vade)
- [ ] Feedback-based accuracy iyileÅŸme %10+
- [ ] TTT latency overhead < 100ms
- [ ] Continuous learning stability
- [ ] Zero catastrophic forgetting

### Faz 11-12 (Uzun Vade)
- [ ] Multi-modal benchmark scores
- [ ] Few-shot adaptation speed
- [ ] Autonomous task completion rate
- [ ] Novel skill acquisition

---

## ğŸ”„ GÃ¼ncelleme GeÃ§miÅŸi

| Tarih | GÃ¼ncelleme |
|-------|------------|
| 04 AralÄ±k 2025 | Gelecek fazlar eklendi (7-12) |
| 03 AralÄ±k 2025 | FAZ 0-6 tamamlandÄ±, 93 test geÃ§ti |

---

*"Yolculuk binlerce adÄ±mla baÅŸlar, ama ilk adÄ±mÄ± atmadan hiÃ§bir yere varamazsÄ±n."* ğŸš€

# ğŸ—ï¸ EVO-TR Sistem Mimarisi

**Bu dÃ¶kÃ¼man versiyondan baÄŸÄ±msÄ±zdÄ±r ve projenin genel sistem mimarisini aÃ§Ä±klar.**

---

## ğŸ¯ Proje Hedefi

**EVO-TR** (Evolvable Turkish AI), Mac Mini M4 Ã¼zerinde Ã§alÄ±ÅŸan, sÃ¼rekli Ã¶ÄŸrenen bir AI asistanÄ±dÄ±r.

### Ana Ã–zellikler
- ğŸ‡¹ğŸ‡· DoÄŸal TÃ¼rkÃ§e iletiÅŸim
- ğŸ Python kod yardÄ±mÄ±
- ğŸ§  KonuÅŸma belleÄŸi (RAG)
- ğŸ”„ SÃ¼rekli Ã¶ÄŸrenme dÃ¶ngÃ¼sÃ¼
- âš¡ Yerel Ã§alÄ±ÅŸma (Apple Silicon optimizasyonu)

---

## ğŸ›ï¸ YÃ¼ksek Seviye Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        KULLANICI ARAYÃœZÃœ                        â”‚
â”‚                   (CLI / Web API / WebSocket)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ORCHESTRATOR                            â”‚
â”‚              (Ä°stek koordinasyonu ve akÄ±ÅŸ kontrolÃ¼)             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                              â”‚
       â–¼                                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ROUTER     â”‚                             â”‚     MEMORY      â”‚
â”‚ (Intent â†’    â”‚                             â”‚   (RAG + Chat   â”‚
â”‚  Expert)     â”‚                             â”‚    History)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                              â”‚
       â–¼                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚              EXPERT LAYER                â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚TR Chat  â”‚ â”‚Python   â”‚ â”‚Math     â”‚    â”‚
â”‚  â”‚Expert   â”‚ â”‚Expert   â”‚ â”‚Expert   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â”‚
â”‚       â”‚           â”‚           â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”‚
â”‚  â”‚tr_chat  â”‚ â”‚python   â”‚ â”‚math     â”‚    â”‚
â”‚  â”‚LoRA     â”‚ â”‚LoRA     â”‚ â”‚LoRA     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MLX INFERENCE ENGINE          â”‚
â”‚         (Base Model + LoRA Fusion)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            QWEN 2.5 3B INSTRUCT          â”‚
â”‚              (Base Model)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ BileÅŸen DetaylarÄ±

### 1. Orchestrator (`src/orchestrator.py`)

Ana koordinatÃ¶r modÃ¼lÃ¼. TÃ¼m bileÅŸenler arasÄ±ndaki iletiÅŸimi yÃ¶netir.

```python
class Orchestrator:
    def __init__(self):
        self.router = ExpertRouter()
        self.memory = ConversationMemory()
        self.experts = {
            "tr_chat": TrChatExpert(),
            "python_coder": PythonExpert(),
            ...
        }
    
    async def process(self, user_input: str) -> str:
        # 1. Memory'den baÄŸlam al
        context = self.memory.get_context(user_input)
        
        # 2. Intent belirle ve expert seÃ§
        intent = self.router.classify(user_input)
        expert = self.experts[intent]
        
        # 3. Expert ile yanÄ±t Ã¼ret
        response = await expert.generate(user_input, context)
        
        # 4. Memory'ye kaydet
        self.memory.store(user_input, response)
        
        return response
```

**Sorumluluklar:**
- âœ… Ä°stek akÄ±ÅŸÄ± koordinasyonu
- âœ… BileÅŸen yaÅŸam dÃ¶ngÃ¼sÃ¼ yÃ¶netimi
- âœ… Hata yÃ¶netimi
- âœ… Logging

---

### 2. Router (`src/router/`)

KullanÄ±cÄ± girdisini analiz ederek doÄŸru uzmanÄ± seÃ§er.

```
router/
â”œâ”€â”€ intent_classifier.py   # Intent sÄ±nÄ±flandÄ±rma
â””â”€â”€ expert_router.py       # Expert seÃ§imi
```

**Intent TÃ¼rleri:**
| Intent | AÃ§Ä±klama | Expert |
|--------|----------|--------|
| `tr_chat` | TÃ¼rkÃ§e genel sohbet | TrChatExpert |
| `python_code` | Python programlama | PythonExpert |
| `math` | Matematik sorularÄ± | MathExpert |
| `history` | Tarih sorularÄ± | HistoryExpert |
| `science` | Bilim sorularÄ± | ScienceExpert |

**YÃ¶nlendirme MantÄ±ÄŸÄ±:**
```python
def classify(self, text: str) -> str:
    # 1. Keyword matching
    # 2. Embedding similarity
    # 3. Fallback: tr_chat
    return intent
```

---

### 3. Experts (`src/experts/`)

Her alan iÃ§in Ã¶zelleÅŸmiÅŸ uzman modÃ¼lleri.

```
experts/
â”œâ”€â”€ base_expert.py         # TÃ¼m expertler iÃ§in temel sÄ±nÄ±f
â”œâ”€â”€ tr_chat_expert.py      # TÃ¼rkÃ§e sohbet
â”œâ”€â”€ python_expert.py       # Python programlama
â”œâ”€â”€ math_expert.py         # Matematik
â”œâ”€â”€ history_expert.py      # Tarih
â””â”€â”€ science_expert.py      # Bilim
```

**Expert YapÄ±sÄ±:**
```python
class BaseExpert:
    def __init__(self, adapter_path: str):
        self.adapter_path = adapter_path
        self.system_prompt = "..."
    
    def prepare_prompt(self, user_input: str, context: str) -> str:
        ...
    
    async def generate(self, user_input: str, context: str) -> str:
        prompt = self.prepare_prompt(user_input, context)
        return await self.inference.generate(prompt, self.adapter_path)
```

---

### 4. Inference Engine (`src/inference/`)

MLX tabanlÄ± model Ã§Ä±karÄ±m motoru.

```
inference/
â”œâ”€â”€ base_inference.py      # Temel inference sÄ±nÄ±fÄ±
â”œâ”€â”€ mlx_inference.py       # MLX implementasyonu
â””â”€â”€ adapter_manager.py     # LoRA adaptÃ¶r yÃ¶netimi
```

**Ã–zellikler:**
- âš¡ Apple Silicon optimizasyonu (Metal GPU)
- ğŸ”„ Dinamik LoRA yÃ¼kleme/boÅŸaltma
- ğŸ§µ Async generation desteÄŸi
- ğŸ“Š Token/performans metrikleri

```python
class MLXInference:
    def __init__(self, base_model_path: str):
        self.model = load_model(base_model_path)
        self.tokenizer = load_tokenizer(base_model_path)
    
    async def generate(self, prompt: str, adapter_path: str = None) -> str:
        if adapter_path:
            model = fuse_lora(self.model, adapter_path)
        
        tokens = self.tokenizer.encode(prompt)
        output = model.generate(tokens, ...)
        return self.tokenizer.decode(output)
```

---

### 5. Memory System (`src/memory/`)

KonuÅŸma belleÄŸi ve RAG sistemi.

```
memory/
â”œâ”€â”€ conversation_memory.py  # KÄ±sa/uzun sÃ¼reli bellek
â”œâ”€â”€ chroma_store.py         # ChromaDB vektÃ¶r deposu
â””â”€â”€ rag_retriever.py        # Retrieval-Augmented Generation
```

**Bellek KatmanlarÄ±:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          KISA SÃœRELÄ° BELLEK             â”‚
â”‚    (Son N konuÅŸma - in-memory)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          UZUN SÃœRELÄ° BELLEK             â”‚
â”‚         (ChromaDB - persistent)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            RAG RETRIEVER                â”‚
â”‚  (Semantic search + context assembly)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 6. Lifecycle Management (`src/lifecycle/`)

SÃ¼rekli Ã¶ÄŸrenme ve adaptasyon.

```
lifecycle/
â”œâ”€â”€ active_learning.py      # Aktif Ã¶ÄŸrenme
â”œâ”€â”€ incremental_trainer.py  # ArtÄ±mlÄ± eÄŸitim
â””â”€â”€ preference_learning.py  # Tercih Ã¶ÄŸrenme
```

**Ã–ÄŸrenme DÃ¶ngÃ¼sÃ¼:**
```
KullanÄ±cÄ± Geri Bildirimi
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feedback Toplama â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Veri HazÄ±rlama  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Incremental     â”‚
â”‚ LoRA Training   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AdaptÃ¶r         â”‚
â”‚ GÃ¼ncelleme      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 7. Web Interface (`src/web/`)

REST API ve WebSocket desteÄŸi.

```
web/
â”œâ”€â”€ api.py           # FastAPI REST endpoints
â””â”€â”€ websocket.py     # Real-time WebSocket
```

**API Endpoints:**
| Method | Endpoint | AÃ§Ä±klama |
|--------|----------|----------|
| POST | `/chat` | Sohbet mesajÄ± gÃ¶nder |
| GET | `/history` | KonuÅŸma geÃ§miÅŸi |
| POST | `/feedback` | Geri bildirim gÃ¶nder |
| GET | `/health` | Sistem durumu |

---

## ğŸ”„ Veri AkÄ±ÅŸÄ±

### Sohbet AkÄ±ÅŸÄ±

```
1. KullanÄ±cÄ± mesaj girer
   â””â”€â–º CLI/Web API

2. Orchestrator mesajÄ± alÄ±r
   â”œâ”€â–º Memory'den baÄŸlam Ã§eker
   â””â”€â–º Router'a intent sorgusu

3. Router intent belirler
   â””â”€â–º "python_code", "tr_chat", vs.

4. Ä°lgili Expert seÃ§ilir
   â””â”€â–º PythonExpert, TrChatExpert, vs.

5. Expert prompt hazÄ±rlar
   â”œâ”€â–º System prompt
   â”œâ”€â–º Context (memory'den)
   â””â”€â–º User input

6. MLX Inference Ã§alÄ±ÅŸÄ±r
   â”œâ”€â–º Base model yÃ¼kle
   â”œâ”€â–º LoRA adaptÃ¶r fuse et
   â””â”€â–º Generate

7. YanÄ±t kullanÄ±cÄ±ya dÃ¶ner
   â””â”€â–º Memory'ye kaydet
```

---

## ğŸ› ï¸ Teknoloji Stack

### Core
| BileÅŸen | Teknoloji | Versiyon |
|---------|-----------|----------|
| Runtime | Python | 3.11+ |
| ML Framework | MLX | 0.30+ |
| LLM Library | mlx_lm | 0.28+ |
| Vector DB | ChromaDB | 0.4+ |

### Model
| BileÅŸen | Model | Boyut |
|---------|-------|-------|
| Base Model | Qwen-2.5-3B-Instruct | ~6GB |
| LoRA Rank | 8-16 | ~50MB/adaptÃ¶r |

### API
| BileÅŸen | Teknoloji |
|---------|-----------|
| REST API | FastAPI |
| WebSocket | Starlette |
| Async | asyncio |

### Veri
| BileÅŸen | Format |
|---------|--------|
| Training Data | JSONL (messages format) |
| Config | YAML |
| Logs | JSONL |

---

## ğŸ“Š Performans Hedefleri

| Metrik | Hedef | AÃ§Ä±klama |
|--------|-------|----------|
| Latency (ilk token) | <500ms | Ä°lk token Ã¼retim sÃ¼resi |
| Throughput | 30+ tok/s | Token Ã¼retim hÄ±zÄ± |
| Memory | <8GB | Maksimum RAM kullanÄ±mÄ± |
| LoRA Switch | <1s | AdaptÃ¶r deÄŸiÅŸtirme sÃ¼resi |

---

## ğŸ”’ GÃ¼venlik

### API AnahtarlarÄ±
- `.env` dosyasÄ±nda saklanÄ±r
- Git'e dahil edilmez (`.gitignore`)
- Environment variables olarak yÃ¼klenir

### Veri GizliliÄŸi
- TÃ¼m veriler yerel makinede
- Cloud'a veri gÃ¶nderilmez
- KonuÅŸma loglarÄ± ÅŸifrelenebilir

---

## ğŸ“ˆ Ã–lÃ§eklenebilirlik

### Yatay Ã–lÃ§ekleme
- Birden fazla expert paralel Ã§alÄ±ÅŸabilir
- FarklÄ± domainler iÃ§in yeni expertler eklenebilir

### Dikey Ã–lÃ§ekleme
- Daha bÃ¼yÃ¼k base model kullanÄ±labilir (7B, 14B)
- Daha yÃ¼ksek LoRA rank
- Daha fazla training verisi

---

## ğŸ§ª Test Stratejisi

```
tests/
â”œâ”€â”€ Unit Tests           # BileÅŸen bazlÄ± testler
â”œâ”€â”€ Integration Tests    # BileÅŸenler arasÄ± testler
â””â”€â”€ E2E Tests           # UÃ§tan uca testler
```

**Test Ã‡alÄ±ÅŸtÄ±rma:**
```bash
# TÃ¼m testler
pytest tests/

# Belirli modÃ¼l
pytest tests/test_router.py

# Coverage
pytest --cov=src tests/
```

---

## ğŸ”§ GeliÅŸtirme OrtamÄ±

### Kurulum
```bash
# Virtual environment
python -m venv .venv
source .venv/bin/activate

# BaÄŸÄ±mlÄ±lÄ±klar
pip install -r requirements.txt

# Model indirme
python scripts/download_base_model.py
```

### GeliÅŸtirme DÃ¶ngÃ¼sÃ¼
1. Feature branch oluÅŸtur
2. Testleri yaz
3. Kodu geliÅŸtir
4. Testleri Ã§alÄ±ÅŸtÄ±r
5. PR oluÅŸtur

---

## ğŸ“š Ä°lgili DÃ¶kÃ¼manlar

- [PROJECT-STRUCTURE.md](./PROJECT-STRUCTURE.md) - Dizin yapÄ±sÄ±
- [COMPONENTS.md](./COMPONENTS.md) - BileÅŸen detaylarÄ±
- [v2/TODO.md](../v2/TODO.md) - GÃ¼ncel gÃ¶revler
- [v2/MEMORY.md](../v2/MEMORY.md) - GÃ¼ncel durum
